{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5c9d42",
   "metadata": {},
   "source": [
    "# LangGraph Agent with Web Search\n",
    "\n",
    "This notebook demonstrates a multi-node AI agent using LangGraph that can:\n",
    "- Decide if a query needs web search\n",
    "- Perform web searches using Tavily\n",
    "- Generate intelligent responses based on search results or knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdbe76",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies\n",
    "\n",
    "Required packages:\n",
    "- langgraph\n",
    "- langchain\n",
    "- langchain-openai\n",
    "- langchain-community\n",
    "- tavily-python\n",
    "- python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63118e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install packages\n",
    "# !pip install langgraph langchain langchain-openai langchain-community tavily-python python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24360ff5",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b37b4522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import operator\n",
    "from langchain_core.runnables.graph_ascii import draw_ascii \n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Load environment variables (set OPENAI_API_KEY and TAVILY_API_KEY first)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b07579",
   "metadata": {},
   "source": [
    "## 3. Define the Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15e8ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[dict], operator.add]  # Accumulates conversation history\n",
    "    needs_search: bool  # Flag to determine if web search is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2863550d",
   "metadata": {},
   "source": [
    "## 4. Initialize Tools & LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24399a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM and search tool initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Check for required environment variables\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "if not openai_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables. Please set it in your .env file.\")\n",
    "if not tavily_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY not found in environment variables. Please set it in your .env file.\")\n",
    "\n",
    "# Initialize LLM and search tool\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "search_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "print(\"‚úÖ LLM and search tool initialized successfully!\")\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-opus-4-6\",  # or \"claude-3-haiku-20240307\"\n",
    "    temperature=0,\n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a0b5e",
   "metadata": {},
   "source": [
    "## 5. Define Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9586dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_search_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Decide if we need to search the web based on the query.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"Determine if this query requires current/real-time information \"\n",
    "            \"or factual verification that might change over time. \"\n",
    "            \"Respond ONLY with 'yes' or 'no'.\"\n",
    "        ),\n",
    "        HumanMessage(content=f\"Query: {state['messages'][-1]['content']}\")\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    needs_search = \"yes\" in response.content.lower()\n",
    "    return {\"needs_search\": needs_search}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e061fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Perform web search and add results to conversation.\"\"\"\n",
    "    query = state[\"messages\"][-1][\"content\"]\n",
    "    results = search_tool.invoke({\"query\": query})\n",
    "    \n",
    "    # Format search results\n",
    "    formatted_results = \"\\n\".join([\n",
    "        f\"Result {i+1}: {res['content']}\" \n",
    "        for i, res in enumerate(results)\n",
    "    ])\n",
    "    \n",
    "    # Add search results as an AI message\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"Search results for '{query}':\\n{formatted_results}\"\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2da897fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate final response using conversation history.\"\"\"\n",
    "    # Extract the original user query (first message)\n",
    "    user_query = None\n",
    "    search_results = None\n",
    "    \n",
    "    for msg in state[\"messages\"]:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            user_query = msg[\"content\"]\n",
    "        elif msg[\"role\"] == \"assistant\" and \"Search results\" in msg[\"content\"]:\n",
    "            search_results = msg[\"content\"]\n",
    "    \n",
    "    # Build messages ensuring conversation ends with user message\n",
    "    messages = [SystemMessage(content=\"You are a helpful assistant. Answer the user's question based on the provided information.\")]\n",
    "    \n",
    "    if search_results:\n",
    "        # Add search results as context\n",
    "        messages.append(AIMessage(content=search_results))\n",
    "    \n",
    "    # Always end with user message\n",
    "    messages.append(HumanMessage(content=user_query or state[\"messages\"][-1][\"content\"]))\n",
    "    print(messages)\n",
    "    response = llm.invoke(messages)\n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": response.content}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e5923",
   "metadata": {},
   "source": [
    "## 6. Define Conditional Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efa6a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_decision(state: AgentState) -> str:\n",
    "    \"\"\"Route to search or direct response based on decision.\"\"\"\n",
    "    return \"search\" if state[\"needs_search\"] else \"respond\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e154e",
   "metadata": {},
   "source": [
    "## 7. Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49c3b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"decide\", should_search_node)\n",
    "workflow.add_node(\"search\", search_node)\n",
    "workflow.add_node(\"respond\", respond_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"decide\")\n",
    "\n",
    "# Add edges with conditional routing\n",
    "workflow.add_conditional_edges(\n",
    "    \"decide\",\n",
    "    route_after_decision,\n",
    "    {\"search\": \"search\", \"respond\": \"respond\"}\n",
    ")\n",
    "workflow.add_edge(\"search\", \"respond\")\n",
    "workflow.add_edge(\"respond\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfe73802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Agent Graph Structure:\n",
      "==================================================\n",
      "         +-----------+      \n",
      "         | __start__ |      \n",
      "         +-----------+      \n",
      "               *            \n",
      "               *            \n",
      "               *            \n",
      "          +--------+        \n",
      "          | decide |        \n",
      "          +--------+        \n",
      "          ..        ..      \n",
      "        ..            ..    \n",
      "       .                ..  \n",
      "+--------+                . \n",
      "| search |              ..  \n",
      "+--------+            ..    \n",
      "          **        ..      \n",
      "            **    ..        \n",
      "              *  .          \n",
      "          +---------+       \n",
      "          | respond |       \n",
      "          +---------+       \n",
      "               *            \n",
      "               *            \n",
      "               *            \n",
      "          +---------+       \n",
      "          | __end__ |       \n",
      "          +---------+       \n"
     ]
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "from langchain_core.runnables.graph_ascii import draw_ascii \n",
    "print(\"üìä Agent Graph Structure:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Print ASCII representation\n",
    "print(app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06026b0a",
   "metadata": {},
   "source": [
    "## 8. Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05ac0d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Example 1: Current events question\n",
      "\n",
      "Answer: # Major AI Announcements at CES 2026\n",
      "\n",
      "CES 2026 (January 6-9, Las Vegas) marked a significant shift for AI, moving from digital interfaces into the **physical world** through physical AI and proactive agents. Here are the key announcements:\n",
      "\n",
      "## NVIDIA's Rubin Platform\n",
      "The biggest announcement was **NVIDIA's launch of the Vera Rubin architecture**, replacing the Blackwell series. Key highlights include:\n",
      "- A suite of **six new chips**, including the Vera CPU and Rubin GPU\n",
      "- **5x the performance** of Blackwell\n",
      "- **10x reduction** in inference token costs\n",
      "- **4x fewer GPUs** needed to train Mixture-of-Experts (MoE) models\n",
      "- A new **Inference Context Memory Storage platform** using BlueField-4 processors to accelerate multistep agentic reasoning\n",
      "- Major cloud providers (**Microsoft, AWS, Google, CoreWeave**) and partners (Cisco, Dell, HPE, Lenovo) committed to deploying Rubin-based superfactories in the second half of 2026\n",
      "\n",
      "## AMD's Data Center Push\n",
      "- CEO Lisa Su unveiled the forthcoming **\"Helios\" AI server rack** and the **Instinct MI400 GPU series**\n",
      "\n",
      "## Qualcomm's Edge AI Solutions\n",
      "- New processors for **edge AI deployment**, including:\n",
      "  - **Qualcomm Insight Platform** for AI-powered video intelligence\n",
      "  - **Qualcomm Terrestrial Positioning Services** for precise positioning\n",
      "  - **Edge Impulse platform** for inference and training workloads\n",
      "\n",
      "## Other Notable Developments\n",
      "- **Intel, AMD, and Qualcomm** unveiled high-performance **neural processing units (NPUs)** for AI PCs enabling local execution of massive models\n",
      "- **Production-ready humanoids** like the electric **Boston Dynamics Atlas** were featured\n",
      "- **HP launched the EliteBoard G1a**, an AI PC in a keyboard\n",
      "\n",
      "Overall, CES 2026 signaled that AI infrastructure spending has become central to the economy, with even traditionally consumer-focused shows pivoting heavily toward data center and enterprise AI announcements.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Question needing search\n",
    "print(\"üîç Example 1: Current events question\")\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What were the major AI announcements at CES 2026?\"}], \"needs_search\": False}\n",
    "result = app.invoke(inputs)\n",
    "print(\"Answer:\", result[\"messages\"][-1][\"content\"])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea564ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Example 2: General knowledge question\n",
      "\n",
      "Answer: # Photosynthesis\n",
      "\n",
      "Photosynthesis is the process by which plants, algae, and some bacteria convert light energy into chemical energy (glucose), using carbon dioxide and water. It is fundamental to life on Earth.\n",
      "\n",
      "## Overall Equation\n",
      "\n",
      "**6CO‚ÇÇ + 6H‚ÇÇO + light energy ‚Üí C‚ÇÜH‚ÇÅ‚ÇÇO‚ÇÜ + 6O‚ÇÇ**\n",
      "\n",
      "## The Two Main Stages\n",
      "\n",
      "### 1. Light-Dependent Reactions (in the thylakoid membranes)\n",
      "- **Light absorption:** Chlorophyll and other pigments in photosystems (PS II and PS I) capture sunlight.\n",
      "- **Water splitting (photolysis):** Water molecules are split into hydrogen ions (H‚Å∫), electrons, and **oxygen** (released as a byproduct).\n",
      "- **Electron transport chain:** Excited electrons pass through a series of proteins, releasing energy used to pump H‚Å∫ ions across the membrane.\n",
      "- **ATP & NADPH production:** The H‚Å∫ gradient drives ATP synthase to produce **ATP**, and electrons ultimately reduce NADP‚Å∫ to form **NADPH**.\n",
      "\n",
      "### 2. Light-Independent Reactions / Calvin Cycle (in the stroma)\n",
      "- **Carbon fixation:** CO‚ÇÇ is attached to a 5-carbon molecule (RuBP) by the enzyme **RuBisCO**, forming two 3-carbon molecules (3-PGA).\n",
      "- **Reduction:** ATP and NADPH from the light reactions are used to convert 3-PGA into **G3P** (glyceraldehyde-3-phosphate).\n",
      "- **Regeneration:** Most G3P molecules are recycled to regenerate RuBP, allowing the cycle to continue.\n",
      "- **Output:** Some G3P exits the cycle and is used to build **glucose** and other organic molecules.\n",
      "\n",
      "## Why It Matters\n",
      "- **Produces oxygen** that most living organisms need to breathe\n",
      "- **Converts solar energy** into chemical energy that fuels food chains\n",
      "- **Removes CO‚ÇÇ** from the atmosphere, playing a key role in the carbon cycle\n",
      "\n",
      "In essence, photosynthesis captures the sun's energy and stores it in the bonds of sugar molecules, sustaining nearly all life on Earth.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Question answerable without search\n",
    "print(\"üí° Example 2: General knowledge question\")\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"Explain how photosynthesis works\"}], \"needs_search\": False}\n",
    "result = app.invoke(inputs)\n",
    "print(\"Answer:\", result[\"messages\"][-1][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
